{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:1\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "UNK_token = 3  # Unkonw token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\", UNK_token:\"UNK\"}\n",
    "        self.num_words = 4  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {\"PAD\": PAD_token, \"SOS\": SOS_token, \"EOS\": EOS_token, \"UNK\":UNK_token}\n",
    "        self.word2count = {\"UNK\": 0}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\", UNK_token:\"UNK\"}\n",
    "        self.num_words = 4 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"can't\", r\"can not\", s)\n",
    "    s = re.sub(r\"n't\", r\" not\", s)\n",
    "    s = re.sub(r\"'ve'\", r\" have\", s)\n",
    "    s = re.sub(r\"cannot\", r\"can not\", s)\n",
    "    s = re.sub(r\"what's\", r\"what is\", s)\n",
    "    s = re.sub(r\"'re\", r\" are\", s)\n",
    "    s = re.sub(r\"'d\", r\" would\", s)\n",
    "    s = re.sub(r\"'ll'\", r\" will\", s)\n",
    "    s = re.sub(r\" im \", r\" i am \", s)\n",
    "    s = re.sub(r\"'m\", r\" am\", s)\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?0-9]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "wiki_docs = [0]*30\n",
    "path = '../WikiData'\n",
    "for file in os.listdir(path):\n",
    "    wiki_file = open(os.path.join(path,file))\n",
    "    wiki_data = json.load(wiki_file)\n",
    "    wiki_docs[wiki_data['wikiDocumentIdx']] = wiki_data\n",
    "\n",
    "wiki_strings = []\n",
    "for i in range(30):\n",
    "    doc = []\n",
    "    for j in range(4):\n",
    "        doc.append(normalizeString(str(wiki_docs[i][str(j)])))\n",
    "    wiki_strings.append(doc)\n",
    "\n",
    "# print(wikiStrings[20][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readConvsFile(path,file):\n",
    "    conv_file = open(os.path.join(conv_path,file))\n",
    "    conv_data = json.load(conv_file)\n",
    "    wikiIndex = conv_data['wikiDocumentIdx']\n",
    "    if len(conv_data['whoSawDoc']) == 2:\n",
    "        saw = 2\n",
    "    elif conv_data['whoSawDoc'] == ['user1']:\n",
    "        saw = 0\n",
    "    else:\n",
    "        saw = 1\n",
    "    convs = []\n",
    "    for idx, utter in enumerate(conv_data['history']):\n",
    "        utter['text'] = normalizeString(utter['text'])\n",
    "        line = {}\n",
    "        line['wikiIdx'] = wikiIndex\n",
    "        line['docIdx'] = utter['docIdx']\n",
    "        line['uid'] = utter['uid']\n",
    "        line['text'] = utter['text']\n",
    "        line['saw'] = saw\n",
    "        convs.append(line)\n",
    "    \n",
    "    return convs\n",
    "\n",
    "def saveNewConvs(path):\n",
    "    index = 0\n",
    "    for file in os.listdir(path):\n",
    "        if file.split('.')[1] != 'json':\n",
    "            continue\n",
    "        convs = readConvsFile(path,file)\n",
    "        new_file = 'train'+str(index)+'.csv'\n",
    "        data_file = os.path.join(path,new_file)\n",
    "        print('Writing to new formatted line...',index)\n",
    "        df = pd.DataFrame(convs)\n",
    "        df.to_csv(data_file,encoding='utf-8',sep='\\t')\n",
    "        index += 1\n",
    "\n",
    "# conv_path = '../Conversations/train'\n",
    "# saveNewConvs(conv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preparing training data...\n",
      "Read 72922 sentence pairs\n",
      "Trimmed to 58307 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 17425\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 25  # Maximum sentence length to consider\n",
    "\n",
    "def buildPairs(df):\n",
    "    pairs = []\n",
    "    for i in df.index:\n",
    "\n",
    "        pair = []\n",
    "        pair.append(df.iloc[i].wikiIdx)\n",
    "        pair.append(df.iloc[i].docIdx)\n",
    "        pair.append(df.iloc[i].text)\n",
    "        if i+1 < len(df.index) and df.iloc[i].uid != df.iloc[i+1].uid:\n",
    "            pair.append(df.iloc[i+1].text)\n",
    "            pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    try:\n",
    "        # Input sequences need to preserve the last word for EOS token\n",
    "        return type(p[2]) == str and type(p[3]) == str and len(p[2].split(' ')) < MAX_LENGTH and len(p[3].split(' ')) < MAX_LENGTH\n",
    "    except Exception as e:\n",
    "        print(p)\n",
    "        raise e\n",
    "        \n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def loadPrepareData(dataPath,corpus_name,wiki_strings):\n",
    "    voc = Voc(corpus_name)\n",
    "    pairs = []\n",
    "    print(\"Starting preparing training data...\")\n",
    "    for file in os.listdir(dataPath):\n",
    "        if file.split('.')[1] == 'json':\n",
    "            continue\n",
    "        df = pd.read_csv(os.path.join(dataPath,file),sep='\\t',encoding='utf-8')\n",
    "        pairs += buildPairs(df)\n",
    "\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[2])\n",
    "        voc.addSentence(pair[3])\n",
    "    \n",
    "    for wiki_doc in wiki_strings:\n",
    "        for s in wiki_doc:\n",
    "            voc.addSentence(s)\n",
    "            \n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "corpus_name = 'seq+att'\n",
    "save_dir = os.path.join('../Conversations',corpus_name)\n",
    "voc, pairs = loadPrepareData('../Conversations/train',corpus_name,wiki_strings)\n",
    "\n",
    "# print(\"\\npairs:\")\n",
    "# for pair in pairs[:30]:\n",
    "#     print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 12746 / 17421 = 0.7316\n",
      "\n",
      "pairs:\n",
      "[5, 0, 'hey have you seen the inception ?', 'no i have not but have heard of it . what is it about']\n",
      "[5, 0, 'no i have not but have heard of it . what is it about', 'it s about extractors that perform experiments using military technology o n people to retrieve info about their targets .']\n",
      "[5, 0, 'it s about extractors that perform experiments using military technology o n people to retrieve info about their targets .', 'sounds interesting do you know which actors are in it ?']\n",
      "[5, 0, 'he plays as don cobb', 'oh okay yeah i am not a big scifi fan but there are a few movies i still enjoy in that genre .']\n",
      "[5, 0, 'is it a long movie ?', 'does not say how long it is .']\n",
      "[5, 2, 'ellen page', 'oh cool . i am familiar with her . she s in a number of good movies and is great .']\n",
      "[5, 2, 'oh cool . i am familiar with her . she s in a number of good movies and is great .', 'she plays ariadne she is a graduate student that constructs the dreamscapes they are like mazes .']\n",
      "[5, 2, 'she plays ariadne she is a graduate student that constructs the dreamscapes they are like mazes .', 'hmm interesting . do you know if it s an action movie or mostly just scifi ?']\n",
      "[5, 3, 'hmm interesting . do you know if it s an action movie or mostly just scifi ?', 'says scientific']\n",
      "[5, 3, 'says scientific', 'certainly seems unique . do you know if it is based off a book or a previous work ?']\n",
      "[28, 0, 'hello .', 'hello']\n",
      "[28, 0, 'what movie do you like ?', 'well i like comedy .']\n",
      "[28, 0, 'well i like comedy .', 'which movie ?']\n",
      "[28, 0, 'which movie ?', 'i should be asking you this question .']\n",
      "[28, 0, 'what is the name of the movie ?', 'i like faster furious']\n",
      "[28, 0, 'i like faster furious', 'is this the movie that you have the doment of ?']\n",
      "[28, 0, 'is this the movie that you have the doment of ?', 'yes some']\n",
      "[28, 1, 'yes some', 'fast and furious is in your document ?']\n",
      "[28, 1, 'fast and furious is in your document ?', 'yes']\n",
      "[28, 1, 'yes', 'ok .']\n",
      "[28, 1, 'yes i like that movie a lot .', 'what is in your document ?']\n",
      "[28, 1, 'what is in your document ?', 'i do not have one .']\n",
      "[28, 1, 'i do not have one .', 'what scene did you like ?']\n",
      "[28, 2, 'what scene did you like ?', 'i really would like to watch that movie . which part it is ?']\n",
      "[28, 2, 'i really would like to watch that movie . which part it is ?', 'it is in 7']\n",
      "[28, 2, 'it is in 7', 'ok .']\n",
      "[28, 2, 'can you tell me more about this movie ?', 'next i like thriller movie']\n",
      "[28, 2, 'next i like thriller movie', 'ok . can you tell me more aboutit ?']\n",
      "[28, 2, 'ok . can you tell me more aboutit ?', 'ok i like conjuring movie very much']\n",
      "[28, 3, 'ok i like conjuring movie very much', 'i would like to watch one . but i am kind of need more information towards that .']\n",
      "['cast kristen bell as anna the 18 year old princess of arendelle and elsa s younger sister livvy stubenrauch as 5 year old anna katie lopez as 5 year old anna singing agatha lee monn as 9 year old anna idina menzel as elsa the 21 year old snow queen of arendelle and anna s elder sister eva bella as 8 year old elsa spencer lacey UNK as 12 year old elsa jonathan groff as kristoff an iceman who is accompanied by a reindeer named sven tyree brown as 8 year old kristoff critical response the best animated musical to come out of disney since the tragic death of lyricist howard ashman whose work on the little mermaid and beauty and the beast helped build the studio s modern animated division into what it is today . while it lags the UNK bit on its way to the conclusion the script . . . really delivers it offers characters to care about along with some nifty twists and surprises along the way . you can practically see the broadway musical frozen is destined to become while watching disney s 3d animated princess tale . a great big snowy pleasure with an emotionally gripping core brilliant broadway style songs and a crafty plot . its first and third acts are better than the jokey middle but this is the rare example of a walt disney animation studios effort that reaches as deep as a pixar film . frozen is both a declaration of disney s renewed cultural relevance and a UNK of disney coming to terms with its own legacy and its own identity . it s also a just plain terrific bit of family entertainment . wouldirector chris buck jennifer lee genre comedy adventure animation introduction frozen is a 2013 american 3d computer animated musical fantasy film produced by walt disney animation studios and released by walt disney pictures . it is the 53rd disney animated feature film . inspired by hans christian andersen s fairy tale the snow queen the film tells the story of a fearless princess who sets off on a journey alongside a rugged iceman his loyal pet reindeer and a UNK ve snowman to find her estranged sister whose icy powers have inadvertently trapped the kingdom in eternal winter . amoviename frozen rating rotten tomatoes 89 ametacritics 74 100 cinemascore a year 2013', 'princess elsa of arendelle possesses cryokinetic magic often using it to play with her younger sister anna . after elsa accidentally injures anna with her magic their parents the king and queen rush both siblings to a colony of trolls led by grand pabbie . he heals anna but alters her memories to remove UNK of elsa s magic warning elsa that she must learn to control her powers . the king and queen isolate both sisters within the castle . elsa shuts out anna causing a rift between them . elsa suppresses her magic rather than mastering it causing her to become more insecure . when the sisters are teenagers their parents die at sea during a storm .', 'when elsa turns twenty one she is to be crowned queen of arendelle . she is terrified that the kingdom s citizens might find out about her powers and fear for her . the castle gates open to the public and visiting dignitaries for the first time in years . amongst them is the scheming duke of weselton and the dashing prince hans of the southern isles with whom anna falls head over UNK in love . elsa s coronation happens without a hitch but she still remains distant from anna . when hans proposes to anna elsa objects accidentally unleashing her powers before the court . the duke brands her a monster . elsa flees the kingdom but her suppressed magic UNK arendelle in an eternal winter . reaching the north mountain elsa discards her crown and creates a palace of ice in which to live a solitary life .', 'reaching the ice palace anna meets elsa but when she reveals what has become of arendelle elsa becomes agitated and accidentally freezes anna s heart . she then summons a giant snow creature named marshmallow who chases anna kristoff and olaf away . anna s hair begins turning white so kristoff takes her to meet the trolls his adoptive family . grand pabbie reveals that anna will freeze solid unless an act of true love UNK the spell . kristoff races anna back home so hans can give her true love s kiss . hans and his men reach elsa s palace defeating marshmallow and capturing elsa . anna is delivered to hans but rather than kissing her he instead reveals that he has actually been plotting to UNK the throne of arendelle by UNK both sisters . he locks anna in a room to die and manipulates the dignitaries into believing that elsa killed her . he orders the queen s execution only to discover she has escaped her detention cell .']\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 2    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT,wiki_docs):\n",
    "    try:\n",
    "        # Trim words used under the MIN_COUNT from the voc\n",
    "        voc.trim(MIN_COUNT)\n",
    "        # Filter out pairs with trimmed words\n",
    "        keep_pairs = []\n",
    "        for index,pair in enumerate(pairs):\n",
    "            input_sentence = pair[2]\n",
    "            output_sentence = pair[3]\n",
    "            # Check input sentence\n",
    "            for word in input_sentence.split(' '):\n",
    "                if word not in voc.word2index:\n",
    "                    input_sentence = re.sub(\" \"+word+\" \",\" UNK \",input_sentence)\n",
    "                    input_sentence = re.sub(\"^\"+word+\" \",\"UNK \",input_sentence)\n",
    "                    input_sentence = re.sub(\" \"+word+\"$\",\" UNK\",input_sentence)\n",
    "                    input_sentence = re.sub(\"^\"+word+\"$\",\"UNK\",input_sentence)\n",
    "            # Check output sentence\n",
    "            for word in output_sentence.split(' '):\n",
    "                if word not in voc.word2index:\n",
    "                    output_sentence = re.sub(\" \"+word+\" \",\" UNK \",output_sentence)\n",
    "                    output_sentence = re.sub(\"^\"+word+\" \",\"UNK \",output_sentence)\n",
    "                    output_sentence = re.sub(\" \"+word+\"$\",\" UNK\",output_sentence)\n",
    "                    output_sentence = re.sub(\"^\"+word+\"$\",\"UNK\",output_sentence)\n",
    "\n",
    "            pairs[index][2] = input_sentence\n",
    "            pairs[index][3] = output_sentence\n",
    "        \n",
    "        for index, wiki_doc in enumerate(wiki_docs):\n",
    "            for si,section in enumerate(wiki_doc):\n",
    "                for word in section.split(' '):\n",
    "                    if word not in voc.word2index:\n",
    "                        section = re.sub(\" \"+word+\" \",\" UNK \", section)\n",
    "                        section = re.sub(\"^\"+word+\" \",\"UNK \", section)\n",
    "                        section = re.sub(\" \"+word+\"$\",\" UNK\", section)\n",
    "                        section = re.sub(\"^\"+word+\"$\",\"UNK\", section)\n",
    "                        wiki_docs[index][si] = section\n",
    "\n",
    "        return pairs, wiki_docs\n",
    "    except Exception as e:\n",
    "        print(pair)\n",
    "        raise e\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs,wiki_strings = trimRareWords(voc, pairs, MIN_COUNT,wiki_strings)\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:30]:\n",
    "    print(pair)\n",
    "print(wiki_strings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_input: torch.Size([472, 64])\n",
      "doc_lengths: tensor([122, 384, 143, 367, 139, 126, 235, 399, 399, 399, 361, 206, 234, 139,\n",
      "        133, 172, 168, 192, 138, 220, 108, 204, 103, 331, 133, 137, 315, 220,\n",
      "        191, 122, 241, 203, 350,  97, 472, 114, 234, 419, 167, 291, 350, 131,\n",
      "        220, 150, 291, 384, 234, 188, 141, 211, 204, 331, 140, 172, 361, 419,\n",
      "        235, 188, 228,  95, 126, 121, 209, 235])\n",
      "input_variable: tensor([[  118,   128,   177,  ...,   123,  3755,   112],\n",
      "        [   17,    18,     8,  ...,    72,  1390,     2],\n",
      "        [ 2944,    12, 12300,  ...,     2,     2,     0],\n",
      "        ...,\n",
      "        [ 2368,    18,  2258,  ...,     0,     0,     0],\n",
      "        [  362,     2,     2,  ...,     0,     0,     0],\n",
      "        [    2,     0,     0,  ...,     0,     0,     0]])\n",
      "lengths: tensor([24, 23, 23, 21, 21, 21, 20, 20, 20, 19, 17, 16, 16, 16, 16, 15, 15, 15,\n",
      "        14, 14, 13, 13, 13, 12, 12, 11, 11, 10, 10, 10, 10, 10,  9,  9,  9,  8,\n",
      "         8,  8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  5,\n",
      "         5,  5,  5,  5,  5,  4,  4,  3,  3,  2])\n",
      "target_variable: tensor([[  12,   12,  780,  ...,  874,   24,   12],\n",
      "        [ 163,  225,  203,  ...,   18,   22,  697],\n",
      "        [  24,  112, 2844,  ...,   18, 3290,    8],\n",
      "        ...,\n",
      "        [2986,    0,    0,  ...,    0,    0,    0],\n",
      "        [  18,    0,    0,  ...,    0,    0,    0],\n",
      "        [   2,    0,    0,  ...,    0,    0,    0]])\n",
      "mask: tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 25\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "def docPre(docs,voc):\n",
    "    try:\n",
    "        indexes_docs = []\n",
    "        for doc in docs:\n",
    "    #         print(doc)\n",
    "            indexes_docs.append([indexesFromSentence(voc,sentence) for sentence in doc])\n",
    "        return indexes_docs\n",
    "    except Exception as e:\n",
    "        print(doc)\n",
    "        raise e\n",
    "\n",
    "def docVar(l,voc,docs):\n",
    "    indexes_docs = docPre(docs,voc)\n",
    "    indexes_batch = [indexes_docs[docIdx][secIdx] for docIdx,secIdx in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "    \n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch,wiki_docs):\n",
    "    try:\n",
    "        pair_batch.sort(key=lambda x: len(x[2].split(\" \")), reverse=True)\n",
    "        doc_batch, input_batch, output_batch = [], [], []\n",
    "        for pair in pair_batch:\n",
    "            doc_batch.append([pair[0],pair[1]])\n",
    "            input_batch.append(pair[2])\n",
    "            output_batch.append(pair[3])\n",
    "        doc_inp, doc_lengths = docVar(doc_batch, voc,wiki_docs)\n",
    "        inp, lengths = inputVar(input_batch, voc)\n",
    "        output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "        return doc_inp,doc_lengths,inp, lengths, output, mask, max_target_len\n",
    "    except Exception as e:\n",
    "        print(pair_batch)\n",
    "        raise e\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 64\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)],wiki_strings)\n",
    "doc_input, doc_lengths, input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"doc_input:\", doc_input.shape)\n",
    "print(\"doc_lengths:\", doc_lengths)\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)\n",
    "# indexes_batch = [indexesFromSentence(voc, sentence) for sentence in wiki_strings[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size,hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq) # (L,B,E)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)# (L,B,direc*H)  (layer*direc,B,H)\n",
    "        # Unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs) \n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] #(L,B,H)\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output): #(1,B,H) (L,B,H)\n",
    "        return torch.sum(hidden * encoder_output, dim=2) #(L,B)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t() #(B,L)\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) #(B,1,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, embedding_size, encoder_n_layers, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.encoder_n_layers = encoder_n_layers\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(embedding_size+hidden_size*encoder_n_layers, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, sec_hidden, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step) #(1,B,E) \n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        \n",
    "        sec_hidden = sec_hidden[:self.encoder_n_layers] + sec_hidden[self.encoder_n_layers:] #(encoderlayer,B,H)\n",
    "        sec_hidden = sec_hidden.transpose(0,1).contiguous().view(1,embedded.shape[1],-1) #(1,B,encoderlayer*H)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_input = torch.cat((embedded,sec_hidden),2) #融合section与word (1,B,E+H*encoderlayer)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden) #(1,B,H) (layer,B,H)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs) #(B,1,L)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))# (B,1,L) * (B,L,H) = (B,1,H)\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0) #(B,H)\n",
    "        context = context.squeeze(1) #(B,H)\n",
    "        concat_input = torch.cat((rnn_output, context), 1) #(B,2*H)\n",
    "        concat_output = torch.tanh(self.concat(concat_input)) #(B,H)\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)#(B,Out)\n",
    "        output = F.softmax(output, dim=1)#(B,Out)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden #(B,Out) (layer,B,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, section_variable, sec_lengths, sec_idx, target_variable, mask, max_target_len, encoder, sec_encoder, decoder, embedding,\n",
    "          encoder_optimizer, sec_encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    sec_encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    section_variable = section_variable.to(device)\n",
    "    sec_lengths = sec_lengths.to(device)\n",
    "    sec_idx = sec_idx.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "    \n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths) # (L,B,H)  (layer*direc,B,H)\n",
    "    try:\n",
    "        # Forward pass through encoder\n",
    "        sec_outputs, sec_hidden = sec_encoder(section_variable, sec_lengths) # (secL,B,H)  (layer*direc,B,H)\n",
    "        sec_hidden = sec_hidden.index_select(1,sec_idx) #调整回按utter长度排序的batch内顺序\n",
    "    except Exception as e:\n",
    "        print(section_variable,section_variable.shape)\n",
    "        print(sec_lengths,sec_lengths.shape)\n",
    "        print(input_variable,input_variable.shape)\n",
    "        print(lengths,lengths.shape)\n",
    "        raise e\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]]) # (1,B)\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] #（layer,B,H)\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, sec_hidden, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, sec_hidden, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(sec_encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    sec_encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, wiki_strings, encoder, sec_encoder, decoder, encoder_optimizer, sec_encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)],wiki_strings)\n",
    "                                       for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        doc_input, doc_lengths, input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "        \n",
    "        #将doc按长度降序排列，并保存让其恢复原样的idx2\n",
    "        doc_lengths,idx1 = torch.sort(doc_lengths,descending=True)\n",
    "        doc_input = doc_input.index_select(1,idx1)\n",
    "        _,idx2 = torch.sort(idx1)\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, doc_input, doc_lengths, idx2, target_variable, mask, max_target_len, encoder,sec_encoder,\n",
    "                     decoder, embedding, encoder_optimizer,sec_encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'sec_en':sec_encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'sec_en_opt': sec_encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, sec_encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sec_encoder = sec_encoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, sec_seq, sec_length, max_length):\n",
    "        # Forward input and section through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)#(L,1,H) (layer*direc,1,H)\n",
    "        sec_outputs, sec_hidden = self.sec_encoder(sec_seq, sec_length)\n",
    "        \n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, sec_hidden, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Beam(object):\n",
    "    def __init__(self, tokens, log_probs, sec_hidden, decoder_hidden, encoder_outputs):\n",
    "        self.tokens = tokens\n",
    "        self.log_probs = log_probs\n",
    "        self.sec_hidden = sec_hidden\n",
    "        self.decoder_hidden = decoder_hidden\n",
    "        self.encoder_outputs = encoder_outputs\n",
    "        \n",
    "    def extend(self, token, log_prob, sec_hidden, decoder_hidden, encoder_outputs):\n",
    "        return Beam(tokens = self.tokens+[token], \n",
    "                   log_probs = self.log_probs+[log_prob],\n",
    "                   sec_hidden = sec_hidden,\n",
    "                   decoder_hidden = decoder_hidden,\n",
    "                   encoder_outputs = encoder_outputs)\n",
    "    \n",
    "    @property\n",
    "    def latest_token(self):\n",
    "        return self.tokens[-1]\n",
    "    \n",
    "    @property\n",
    "    def avg_log_prob(self):\n",
    "        return sum(self.log_probs)/len(self.tokens)\n",
    "\n",
    "class BeamSearchDecoder(object):\n",
    "    def __init__(self, encoder, sec_encoder, decoder):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sec_encoder = sec_encoder\n",
    "    \n",
    "    def sort_beams(self,beams):\n",
    "        return sorted(beams, key=lambda h: h.avg_log_prob, reverse=True)\n",
    "\n",
    "    def beam_search(self, input_seq, input_length, sec_seq, sec_length, max_length, beam_size):\n",
    "        # Forward input and section through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)#(L,1,H) (layer*direc,1,H)\n",
    "        sec_outputs, sec_hidden = self.sec_encoder(sec_seq, sec_length) #(secL,1,H) (layer*direc,1,H)\n",
    "        \n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layersSOS_tokentokentokentoken      \n",
    "        beams = [Beam(tokens=[SOS_token],\n",
    "                     log_probs=[0.0],\n",
    "                     sec_hidden=sec_hidden,\n",
    "                     decodeencoder_outputsecoder_hidden,\n",
    "                     encoder_ouputs=encoder_outputs) for _ in range(beam_size)]\n",
    "        \n",
    "        results = []\n",
    "        steps = 0\n",
    "        while steps < max_length and len(results) < beam_size:\n",
    "            latest_tokens = [h.latest_token for h in beams]\n",
    "            latest_tokens = torch.LongTensor(latest_tokens,device=device, dtype=torch.long)\n",
    "            \n",
    "            all_decoder_hidden = []\n",
    "            \n",
    "            for h in beams:\n",
    "                all_decoder_hidden.append(h.decoder_hidden.transpose(0,1).contiguous())\n",
    "            \n",
    "            sec_hidden_stack = beams[0].sec_hidden # (layer*direc,1,H)\n",
    "            decoder_hidden_stack = torch.stack(all_decoder_hidden).transpose(0,1).contiguous() # (layer*direc,Beam,H)\n",
    "            encoder_outputs_stack =  beams[0].encoder_outputs # (secL,1,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, sec_encoder, decoder, searcher, voc, sentence, wikiSec, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)] #(1,L)\n",
    "    sec_indexes = [indexesFromSentence(voc,wikiSec)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch]) #(1,)\n",
    "    sec_lengths = torch.tensor([len(indexes) for indexes in sec_indexes])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1) #(L,1)\n",
    "    sec_batch = torch.LongTensor(sec_indexes).transpose(0, 1) \n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    sec_batch = sec_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    sec_lengths = sec_lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, sec_batch, sec_lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, sec_encoder, decoder, searcher, voc, wiki_strings):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            doc_idx = int(input('document index:'))\n",
    "            sec_idx = int(input('section index:'))\n",
    "            sec_sentence = wiki_strings[doc_idx][sec_idx]\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, sec_encoder, decoder, searcher, voc, input_sentence, sec_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 300\n",
    "embedding_size = 100\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 1\n",
    "dropout = 0.3\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    sec_encoder_sd = checkpoint['sec_en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    sec_encoder_optimizer_sd = checkpoint['sec_en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, embedding_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(embedding_size,hidden_size, embedding, encoder_n_layers, dropout)\n",
    "sec_encoder = EncoderRNN(embedding_size,hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding,embedding_size, encoder_n_layers,hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    sec_encoder.load_state_dict(sec_encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "sec_encoder = sec_encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 100; Percent complete: 0.3%; Average loss: 6.6619\n",
      "Iteration: 200; Percent complete: 0.7%; Average loss: 5.7941\n",
      "Iteration: 300; Percent complete: 1.0%; Average loss: 5.6615\n",
      "Iteration: 400; Percent complete: 1.3%; Average loss: 5.5169\n",
      "Iteration: 500; Percent complete: 1.7%; Average loss: 5.4277\n",
      "Iteration: 600; Percent complete: 2.0%; Average loss: 5.3053\n",
      "Iteration: 700; Percent complete: 2.3%; Average loss: 5.1602\n",
      "Iteration: 800; Percent complete: 2.7%; Average loss: 5.1044\n",
      "Iteration: 900; Percent complete: 3.0%; Average loss: 5.0309\n",
      "Iteration: 1000; Percent complete: 3.3%; Average loss: 4.9572\n",
      "Iteration: 1100; Percent complete: 3.7%; Average loss: 4.9141\n",
      "Iteration: 1200; Percent complete: 4.0%; Average loss: 4.8925\n",
      "Iteration: 1300; Percent complete: 4.3%; Average loss: 4.8392\n",
      "Iteration: 1400; Percent complete: 4.7%; Average loss: 4.8028\n",
      "Iteration: 1500; Percent complete: 5.0%; Average loss: 4.7780\n",
      "Iteration: 1600; Percent complete: 5.3%; Average loss: 4.7908\n",
      "Iteration: 1700; Percent complete: 5.7%; Average loss: 4.7061\n",
      "Iteration: 1800; Percent complete: 6.0%; Average loss: 4.7050\n",
      "Iteration: 1900; Percent complete: 6.3%; Average loss: 4.7020\n",
      "Iteration: 2000; Percent complete: 6.7%; Average loss: 4.6305\n",
      "Iteration: 2100; Percent complete: 7.0%; Average loss: 4.6084\n",
      "Iteration: 2200; Percent complete: 7.3%; Average loss: 4.5848\n",
      "Iteration: 2300; Percent complete: 7.7%; Average loss: 4.5709\n",
      "Iteration: 2400; Percent complete: 8.0%; Average loss: 4.5415\n",
      "Iteration: 2500; Percent complete: 8.3%; Average loss: 4.5226\n",
      "Iteration: 2600; Percent complete: 8.7%; Average loss: 4.5023\n",
      "Iteration: 2700; Percent complete: 9.0%; Average loss: 4.4852\n",
      "Iteration: 2800; Percent complete: 9.3%; Average loss: 4.4724\n",
      "Iteration: 2900; Percent complete: 9.7%; Average loss: 4.4613\n",
      "Iteration: 3000; Percent complete: 10.0%; Average loss: 4.4406\n",
      "Iteration: 3100; Percent complete: 10.3%; Average loss: 4.4361\n",
      "Iteration: 3200; Percent complete: 10.7%; Average loss: 4.3874\n",
      "Iteration: 3300; Percent complete: 11.0%; Average loss: 4.3921\n",
      "Iteration: 3400; Percent complete: 11.3%; Average loss: 4.3996\n",
      "Iteration: 3500; Percent complete: 11.7%; Average loss: 4.3380\n",
      "Iteration: 3600; Percent complete: 12.0%; Average loss: 4.3675\n",
      "Iteration: 3700; Percent complete: 12.3%; Average loss: 4.3471\n",
      "Iteration: 3800; Percent complete: 12.7%; Average loss: 4.3342\n",
      "Iteration: 3900; Percent complete: 13.0%; Average loss: 4.3670\n",
      "Iteration: 4000; Percent complete: 13.3%; Average loss: 4.2824\n",
      "Iteration: 4100; Percent complete: 13.7%; Average loss: 4.2991\n",
      "Iteration: 4200; Percent complete: 14.0%; Average loss: 4.2980\n",
      "Iteration: 4300; Percent complete: 14.3%; Average loss: 4.2643\n",
      "Iteration: 4400; Percent complete: 14.7%; Average loss: 4.2551\n",
      "Iteration: 4500; Percent complete: 15.0%; Average loss: 4.2488\n",
      "Iteration: 4600; Percent complete: 15.3%; Average loss: 4.2519\n",
      "Iteration: 4700; Percent complete: 15.7%; Average loss: 4.2197\n",
      "Iteration: 4800; Percent complete: 16.0%; Average loss: 4.2260\n",
      "Iteration: 4900; Percent complete: 16.3%; Average loss: 4.1943\n",
      "Iteration: 5000; Percent complete: 16.7%; Average loss: 4.1791\n",
      "Iteration: 5100; Percent complete: 17.0%; Average loss: 4.1717\n",
      "Iteration: 5200; Percent complete: 17.3%; Average loss: 4.1694\n",
      "Iteration: 5300; Percent complete: 17.7%; Average loss: 4.1725\n",
      "Iteration: 5400; Percent complete: 18.0%; Average loss: 4.1623\n",
      "Iteration: 5500; Percent complete: 18.3%; Average loss: 4.1750\n",
      "Iteration: 5600; Percent complete: 18.7%; Average loss: 4.1437\n",
      "Iteration: 5700; Percent complete: 19.0%; Average loss: 4.1136\n",
      "Iteration: 5800; Percent complete: 19.3%; Average loss: 4.1256\n",
      "Iteration: 5900; Percent complete: 19.7%; Average loss: 4.1061\n",
      "Iteration: 6000; Percent complete: 20.0%; Average loss: 4.1270\n",
      "Iteration: 6100; Percent complete: 20.3%; Average loss: 4.1001\n",
      "Iteration: 6200; Percent complete: 20.7%; Average loss: 4.0831\n",
      "Iteration: 6300; Percent complete: 21.0%; Average loss: 4.0753\n",
      "Iteration: 6400; Percent complete: 21.3%; Average loss: 4.0591\n",
      "Iteration: 6500; Percent complete: 21.7%; Average loss: 4.0720\n",
      "Iteration: 6600; Percent complete: 22.0%; Average loss: 4.0681\n",
      "Iteration: 6700; Percent complete: 22.3%; Average loss: 4.0493\n",
      "Iteration: 6800; Percent complete: 22.7%; Average loss: 4.0559\n",
      "Iteration: 6900; Percent complete: 23.0%; Average loss: 4.0213\n",
      "Iteration: 7000; Percent complete: 23.3%; Average loss: 4.0022\n",
      "Iteration: 7100; Percent complete: 23.7%; Average loss: 4.0175\n",
      "Iteration: 7200; Percent complete: 24.0%; Average loss: 3.9843\n",
      "Iteration: 7300; Percent complete: 24.3%; Average loss: 3.9511\n",
      "Iteration: 7400; Percent complete: 24.7%; Average loss: 3.9844\n",
      "Iteration: 7500; Percent complete: 25.0%; Average loss: 3.9652\n",
      "Iteration: 7600; Percent complete: 25.3%; Average loss: 3.9539\n",
      "Iteration: 7700; Percent complete: 25.7%; Average loss: 3.9645\n",
      "Iteration: 7800; Percent complete: 26.0%; Average loss: 3.9557\n",
      "Iteration: 7900; Percent complete: 26.3%; Average loss: 3.9395\n",
      "Iteration: 8000; Percent complete: 26.7%; Average loss: 3.9386\n",
      "Iteration: 8100; Percent complete: 27.0%; Average loss: 3.9450\n",
      "Iteration: 8200; Percent complete: 27.3%; Average loss: 3.9307\n",
      "Iteration: 8300; Percent complete: 27.7%; Average loss: 3.9072\n",
      "Iteration: 8400; Percent complete: 28.0%; Average loss: 3.9047\n",
      "Iteration: 8500; Percent complete: 28.3%; Average loss: 3.8718\n",
      "Iteration: 8600; Percent complete: 28.7%; Average loss: 3.8888\n",
      "Iteration: 8700; Percent complete: 29.0%; Average loss: 3.8887\n",
      "Iteration: 8800; Percent complete: 29.3%; Average loss: 3.8629\n",
      "Iteration: 8900; Percent complete: 29.7%; Average loss: 3.8826\n",
      "Iteration: 9000; Percent complete: 30.0%; Average loss: 3.8760\n",
      "Iteration: 9100; Percent complete: 30.3%; Average loss: 3.8741\n",
      "Iteration: 9200; Percent complete: 30.7%; Average loss: 3.8544\n",
      "Iteration: 9300; Percent complete: 31.0%; Average loss: 3.8452\n",
      "Iteration: 9400; Percent complete: 31.3%; Average loss: 3.8536\n",
      "Iteration: 9500; Percent complete: 31.7%; Average loss: 3.8181\n",
      "Iteration: 9600; Percent complete: 32.0%; Average loss: 3.8046\n",
      "Iteration: 9700; Percent complete: 32.3%; Average loss: 3.8199\n",
      "Iteration: 9800; Percent complete: 32.7%; Average loss: 3.8111\n",
      "Iteration: 9900; Percent complete: 33.0%; Average loss: 3.8073\n",
      "Iteration: 10000; Percent complete: 33.3%; Average loss: 3.8099\n",
      "Iteration: 10100; Percent complete: 33.7%; Average loss: 3.8078\n",
      "Iteration: 10200; Percent complete: 34.0%; Average loss: 3.8035\n",
      "Iteration: 10300; Percent complete: 34.3%; Average loss: 3.7952\n",
      "Iteration: 10400; Percent complete: 34.7%; Average loss: 3.7816\n",
      "Iteration: 10500; Percent complete: 35.0%; Average loss: 3.7765\n",
      "Iteration: 10600; Percent complete: 35.3%; Average loss: 3.7719\n",
      "Iteration: 10700; Percent complete: 35.7%; Average loss: 3.7582\n",
      "Iteration: 10800; Percent complete: 36.0%; Average loss: 3.7712\n",
      "Iteration: 10900; Percent complete: 36.3%; Average loss: 3.7652\n",
      "Iteration: 11000; Percent complete: 36.7%; Average loss: 3.7338\n",
      "Iteration: 11100; Percent complete: 37.0%; Average loss: 3.7459\n",
      "Iteration: 11200; Percent complete: 37.3%; Average loss: 3.7391\n",
      "Iteration: 11300; Percent complete: 37.7%; Average loss: 3.7583\n",
      "Iteration: 11400; Percent complete: 38.0%; Average loss: 3.7222\n",
      "Iteration: 11500; Percent complete: 38.3%; Average loss: 3.7239\n",
      "Iteration: 11600; Percent complete: 38.7%; Average loss: 3.7295\n",
      "Iteration: 11700; Percent complete: 39.0%; Average loss: 3.7052\n",
      "Iteration: 11800; Percent complete: 39.3%; Average loss: 3.7178\n",
      "Iteration: 11900; Percent complete: 39.7%; Average loss: 3.7032\n",
      "Iteration: 12000; Percent complete: 40.0%; Average loss: 3.6895\n",
      "Iteration: 12100; Percent complete: 40.3%; Average loss: 3.7094\n",
      "Iteration: 12200; Percent complete: 40.7%; Average loss: 3.7106\n",
      "Iteration: 12300; Percent complete: 41.0%; Average loss: 3.6678\n",
      "Iteration: 12400; Percent complete: 41.3%; Average loss: 3.6588\n",
      "Iteration: 12500; Percent complete: 41.7%; Average loss: 3.6606\n",
      "Iteration: 12600; Percent complete: 42.0%; Average loss: 3.6875\n",
      "Iteration: 12700; Percent complete: 42.3%; Average loss: 3.6687\n",
      "Iteration: 12800; Percent complete: 42.7%; Average loss: 3.6668\n",
      "Iteration: 12900; Percent complete: 43.0%; Average loss: 3.6431\n",
      "Iteration: 13000; Percent complete: 43.3%; Average loss: 3.6415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13100; Percent complete: 43.7%; Average loss: 3.6621\n",
      "Iteration: 13200; Percent complete: 44.0%; Average loss: 3.6487\n",
      "Iteration: 13300; Percent complete: 44.3%; Average loss: 3.6334\n",
      "Iteration: 13400; Percent complete: 44.7%; Average loss: 3.6191\n",
      "Iteration: 13500; Percent complete: 45.0%; Average loss: 3.6021\n",
      "Iteration: 13600; Percent complete: 45.3%; Average loss: 3.6255\n",
      "Iteration: 13700; Percent complete: 45.7%; Average loss: 3.6198\n",
      "Iteration: 13800; Percent complete: 46.0%; Average loss: 3.5954\n",
      "Iteration: 13900; Percent complete: 46.3%; Average loss: 3.5918\n",
      "Iteration: 14000; Percent complete: 46.7%; Average loss: 3.5905\n",
      "Iteration: 14100; Percent complete: 47.0%; Average loss: 3.5924\n",
      "Iteration: 14200; Percent complete: 47.3%; Average loss: 3.5920\n",
      "Iteration: 14300; Percent complete: 47.7%; Average loss: 3.5719\n",
      "Iteration: 14400; Percent complete: 48.0%; Average loss: 3.5749\n",
      "Iteration: 14500; Percent complete: 48.3%; Average loss: 3.5974\n",
      "Iteration: 14600; Percent complete: 48.7%; Average loss: 3.5697\n",
      "Iteration: 14700; Percent complete: 49.0%; Average loss: 3.5502\n",
      "Iteration: 14800; Percent complete: 49.3%; Average loss: 3.5614\n",
      "Iteration: 14900; Percent complete: 49.7%; Average loss: 3.5647\n",
      "Iteration: 15000; Percent complete: 50.0%; Average loss: 3.5742\n",
      "Iteration: 15100; Percent complete: 50.3%; Average loss: 3.5614\n",
      "Iteration: 15200; Percent complete: 50.7%; Average loss: 3.5517\n",
      "Iteration: 15300; Percent complete: 51.0%; Average loss: 3.5270\n",
      "Iteration: 15400; Percent complete: 51.3%; Average loss: 3.5560\n",
      "Iteration: 15500; Percent complete: 51.7%; Average loss: 3.5508\n",
      "Iteration: 15600; Percent complete: 52.0%; Average loss: 3.5210\n",
      "Iteration: 15700; Percent complete: 52.3%; Average loss: 3.5391\n",
      "Iteration: 15800; Percent complete: 52.7%; Average loss: 3.5264\n",
      "Iteration: 15900; Percent complete: 53.0%; Average loss: 3.5305\n",
      "Iteration: 16000; Percent complete: 53.3%; Average loss: 3.5224\n",
      "Iteration: 16100; Percent complete: 53.7%; Average loss: 3.5324\n",
      "Iteration: 16200; Percent complete: 54.0%; Average loss: 3.5239\n",
      "Iteration: 16300; Percent complete: 54.3%; Average loss: 3.5062\n",
      "Iteration: 16400; Percent complete: 54.7%; Average loss: 3.5250\n",
      "Iteration: 16500; Percent complete: 55.0%; Average loss: 3.4928\n",
      "Iteration: 16600; Percent complete: 55.3%; Average loss: 3.5093\n",
      "Iteration: 16700; Percent complete: 55.7%; Average loss: 3.4967\n",
      "Iteration: 16800; Percent complete: 56.0%; Average loss: 3.4808\n",
      "Iteration: 16900; Percent complete: 56.3%; Average loss: 3.5017\n",
      "Iteration: 17000; Percent complete: 56.7%; Average loss: 3.4919\n",
      "Iteration: 17100; Percent complete: 57.0%; Average loss: 3.4789\n",
      "Iteration: 17200; Percent complete: 57.3%; Average loss: 3.4702\n",
      "Iteration: 17300; Percent complete: 57.7%; Average loss: 3.4971\n",
      "Iteration: 17400; Percent complete: 58.0%; Average loss: 3.4759\n",
      "Iteration: 17500; Percent complete: 58.3%; Average loss: 3.4601\n",
      "Iteration: 17600; Percent complete: 58.7%; Average loss: 3.4730\n",
      "Iteration: 17700; Percent complete: 59.0%; Average loss: 3.4379\n",
      "Iteration: 17800; Percent complete: 59.3%; Average loss: 3.4679\n",
      "Iteration: 17900; Percent complete: 59.7%; Average loss: 3.4491\n",
      "Iteration: 18000; Percent complete: 60.0%; Average loss: 3.4468\n",
      "Iteration: 18100; Percent complete: 60.3%; Average loss: 3.4547\n",
      "Iteration: 18200; Percent complete: 60.7%; Average loss: 3.4403\n",
      "Iteration: 18300; Percent complete: 61.0%; Average loss: 3.4276\n",
      "Iteration: 18400; Percent complete: 61.3%; Average loss: 3.4367\n",
      "Iteration: 18500; Percent complete: 61.7%; Average loss: 3.4420\n",
      "Iteration: 18600; Percent complete: 62.0%; Average loss: 3.4179\n",
      "Iteration: 18700; Percent complete: 62.3%; Average loss: 3.4413\n",
      "Iteration: 18800; Percent complete: 62.7%; Average loss: 3.4133\n",
      "Iteration: 18900; Percent complete: 63.0%; Average loss: 3.4148\n",
      "Iteration: 19000; Percent complete: 63.3%; Average loss: 3.4208\n",
      "Iteration: 19100; Percent complete: 63.7%; Average loss: 3.3981\n",
      "Iteration: 19200; Percent complete: 64.0%; Average loss: 3.4133\n",
      "Iteration: 19300; Percent complete: 64.3%; Average loss: 3.4238\n",
      "Iteration: 19400; Percent complete: 64.7%; Average loss: 3.3882\n",
      "Iteration: 19500; Percent complete: 65.0%; Average loss: 3.3911\n",
      "Iteration: 19600; Percent complete: 65.3%; Average loss: 3.3845\n",
      "Iteration: 19700; Percent complete: 65.7%; Average loss: 3.3952\n",
      "Iteration: 19800; Percent complete: 66.0%; Average loss: 3.3913\n",
      "Iteration: 19900; Percent complete: 66.3%; Average loss: 3.3790\n",
      "Iteration: 20000; Percent complete: 66.7%; Average loss: 3.3747\n",
      "Iteration: 20100; Percent complete: 67.0%; Average loss: 3.4053\n",
      "Iteration: 20200; Percent complete: 67.3%; Average loss: 3.3774\n",
      "Iteration: 20300; Percent complete: 67.7%; Average loss: 3.3636\n",
      "Iteration: 20400; Percent complete: 68.0%; Average loss: 3.3896\n",
      "Iteration: 20500; Percent complete: 68.3%; Average loss: 3.3725\n",
      "Iteration: 20600; Percent complete: 68.7%; Average loss: 3.3630\n",
      "Iteration: 20700; Percent complete: 69.0%; Average loss: 3.3705\n",
      "Iteration: 20800; Percent complete: 69.3%; Average loss: 3.3544\n",
      "Iteration: 20900; Percent complete: 69.7%; Average loss: 3.3429\n",
      "Iteration: 21000; Percent complete: 70.0%; Average loss: 3.3448\n",
      "Iteration: 21100; Percent complete: 70.3%; Average loss: 3.3487\n",
      "Iteration: 21200; Percent complete: 70.7%; Average loss: 3.3644\n",
      "Iteration: 21300; Percent complete: 71.0%; Average loss: 3.3359\n",
      "Iteration: 21400; Percent complete: 71.3%; Average loss: 3.3125\n",
      "Iteration: 21500; Percent complete: 71.7%; Average loss: 3.3329\n",
      "Iteration: 21600; Percent complete: 72.0%; Average loss: 3.3423\n",
      "Iteration: 21700; Percent complete: 72.3%; Average loss: 3.3452\n",
      "Iteration: 21800; Percent complete: 72.7%; Average loss: 3.3168\n",
      "Iteration: 21900; Percent complete: 73.0%; Average loss: 3.3226\n",
      "Iteration: 22000; Percent complete: 73.3%; Average loss: 3.3298\n",
      "Iteration: 22100; Percent complete: 73.7%; Average loss: 3.3227\n",
      "Iteration: 22200; Percent complete: 74.0%; Average loss: 3.3035\n",
      "Iteration: 22300; Percent complete: 74.3%; Average loss: 3.3104\n",
      "Iteration: 22400; Percent complete: 74.7%; Average loss: 3.2739\n",
      "Iteration: 22500; Percent complete: 75.0%; Average loss: 3.3017\n",
      "Iteration: 22600; Percent complete: 75.3%; Average loss: 3.3018\n",
      "Iteration: 22700; Percent complete: 75.7%; Average loss: 3.3177\n",
      "Iteration: 22800; Percent complete: 76.0%; Average loss: 3.3211\n",
      "Iteration: 22900; Percent complete: 76.3%; Average loss: 3.2924\n",
      "Iteration: 23000; Percent complete: 76.7%; Average loss: 3.2873\n",
      "Iteration: 23100; Percent complete: 77.0%; Average loss: 3.2795\n",
      "Iteration: 23200; Percent complete: 77.3%; Average loss: 3.2534\n",
      "Iteration: 23300; Percent complete: 77.7%; Average loss: 3.2872\n",
      "Iteration: 23400; Percent complete: 78.0%; Average loss: 3.3039\n",
      "Iteration: 23500; Percent complete: 78.3%; Average loss: 3.2713\n",
      "Iteration: 23600; Percent complete: 78.7%; Average loss: 3.2651\n",
      "Iteration: 23700; Percent complete: 79.0%; Average loss: 3.2606\n",
      "Iteration: 23800; Percent complete: 79.3%; Average loss: 3.2814\n",
      "Iteration: 23900; Percent complete: 79.7%; Average loss: 3.2652\n",
      "Iteration: 24000; Percent complete: 80.0%; Average loss: 3.2470\n",
      "Iteration: 24100; Percent complete: 80.3%; Average loss: 3.2556\n",
      "Iteration: 24200; Percent complete: 80.7%; Average loss: 3.2583\n",
      "Iteration: 24300; Percent complete: 81.0%; Average loss: 3.2391\n",
      "Iteration: 24400; Percent complete: 81.3%; Average loss: 3.2641\n",
      "Iteration: 24500; Percent complete: 81.7%; Average loss: 3.2240\n",
      "Iteration: 24600; Percent complete: 82.0%; Average loss: 3.2544\n",
      "Iteration: 24700; Percent complete: 82.3%; Average loss: 3.2337\n",
      "Iteration: 24800; Percent complete: 82.7%; Average loss: 3.2463\n",
      "Iteration: 24900; Percent complete: 83.0%; Average loss: 3.2514\n",
      "Iteration: 25000; Percent complete: 83.3%; Average loss: 3.2226\n",
      "Iteration: 25100; Percent complete: 83.7%; Average loss: 3.2326\n",
      "Iteration: 25200; Percent complete: 84.0%; Average loss: 3.2263\n",
      "Iteration: 25300; Percent complete: 84.3%; Average loss: 3.2303\n",
      "Iteration: 25400; Percent complete: 84.7%; Average loss: 3.2100\n",
      "Iteration: 25500; Percent complete: 85.0%; Average loss: 3.2337\n",
      "Iteration: 25600; Percent complete: 85.3%; Average loss: 3.2190\n",
      "Iteration: 25700; Percent complete: 85.7%; Average loss: 3.2164\n",
      "Iteration: 25800; Percent complete: 86.0%; Average loss: 3.2018\n",
      "Iteration: 25900; Percent complete: 86.3%; Average loss: 3.1931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 26000; Percent complete: 86.7%; Average loss: 3.2042\n",
      "Iteration: 26100; Percent complete: 87.0%; Average loss: 3.2171\n",
      "Iteration: 26200; Percent complete: 87.3%; Average loss: 3.2186\n",
      "Iteration: 26300; Percent complete: 87.7%; Average loss: 3.1725\n",
      "Iteration: 26400; Percent complete: 88.0%; Average loss: 3.1854\n",
      "Iteration: 26500; Percent complete: 88.3%; Average loss: 3.1973\n",
      "Iteration: 26600; Percent complete: 88.7%; Average loss: 3.1571\n",
      "Iteration: 26700; Percent complete: 89.0%; Average loss: 3.1927\n",
      "Iteration: 26800; Percent complete: 89.3%; Average loss: 3.1708\n",
      "Iteration: 26900; Percent complete: 89.7%; Average loss: 3.1778\n",
      "Iteration: 27000; Percent complete: 90.0%; Average loss: 3.1752\n",
      "Iteration: 27100; Percent complete: 90.3%; Average loss: 3.1813\n",
      "Iteration: 27200; Percent complete: 90.7%; Average loss: 3.1813\n",
      "Iteration: 27300; Percent complete: 91.0%; Average loss: 3.1691\n",
      "Iteration: 27400; Percent complete: 91.3%; Average loss: 3.1627\n",
      "Iteration: 27500; Percent complete: 91.7%; Average loss: 3.1784\n",
      "Iteration: 27600; Percent complete: 92.0%; Average loss: 3.1623\n",
      "Iteration: 27700; Percent complete: 92.3%; Average loss: 3.1305\n",
      "Iteration: 27800; Percent complete: 92.7%; Average loss: 3.1621\n",
      "Iteration: 27900; Percent complete: 93.0%; Average loss: 3.1409\n",
      "Iteration: 28000; Percent complete: 93.3%; Average loss: 3.1505\n",
      "Iteration: 28100; Percent complete: 93.7%; Average loss: 3.1623\n",
      "Iteration: 28200; Percent complete: 94.0%; Average loss: 3.1377\n",
      "Iteration: 28300; Percent complete: 94.3%; Average loss: 3.1546\n",
      "Iteration: 28400; Percent complete: 94.7%; Average loss: 3.1409\n",
      "Iteration: 28500; Percent complete: 95.0%; Average loss: 3.1340\n",
      "Iteration: 28600; Percent complete: 95.3%; Average loss: 3.1428\n",
      "Iteration: 28700; Percent complete: 95.7%; Average loss: 3.1172\n",
      "Iteration: 28800; Percent complete: 96.0%; Average loss: 3.1495\n",
      "Iteration: 28900; Percent complete: 96.3%; Average loss: 3.1335\n",
      "Iteration: 29000; Percent complete: 96.7%; Average loss: 3.1112\n",
      "Iteration: 29100; Percent complete: 97.0%; Average loss: 3.1239\n",
      "Iteration: 29200; Percent complete: 97.3%; Average loss: 3.1308\n",
      "Iteration: 29300; Percent complete: 97.7%; Average loss: 3.1296\n",
      "Iteration: 29400; Percent complete: 98.0%; Average loss: 3.1300\n",
      "Iteration: 29500; Percent complete: 98.3%; Average loss: 3.1204\n",
      "Iteration: 29600; Percent complete: 98.7%; Average loss: 3.1158\n",
      "Iteration: 29700; Percent complete: 99.0%; Average loss: 3.1108\n",
      "Iteration: 29800; Percent complete: 99.3%; Average loss: 3.0983\n",
      "Iteration: 29900; Percent complete: 99.7%; Average loss: 3.1191\n",
      "Iteration: 30000; Percent complete: 100.0%; Average loss: 3.1135\n"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 20.0\n",
    "teacher_forcing_ratio = 1\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 3.0\n",
    "n_iteration = 30000\n",
    "print_every = 100\n",
    "save_every = 500\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "sec_encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "sec_encoder_optimizer = optim.Adam(sec_encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    sec_encoder_optimizer.load_state_dict(sec_encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, wiki_strings, encoder, sec_encoder,decoder, encoder_optimizer,sec_encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document index:5\n",
      "section index:0\n",
      "> what do you think of inception ?\n",
      "Bot: i like the movie . about a bit of a few action . a great director . a great director .\n",
      "document index:22\n",
      "section index:2\n",
      "> i love you\n",
      "Bot: i am not sure . i like the movie and the story of the movie . the original and the plot .\n",
      "document index:23\n",
      "section index:2\n",
      "> do you love me ?\n",
      "Bot: yes i do like the movie the music the movie the animation the animation the animation . a\n",
      "document index:23\n",
      "section index:0\n",
      "> you are stupid \n",
      "Bot: i am good movies my kids . kids and adults . kids are good\n",
      "document index:12\n",
      "section index:2\n",
      "> aha\n",
      "Bot: i think you are right the conversation\n",
      "document index:12\n",
      "section index:2\n",
      "> you will not get hurt\n",
      "Bot: i think i will be interested in watching it . like it . like that . man . . .\n",
      "document index:21\n",
      "section index:0\n",
      "> do you love me ?\n",
      "Bot: i do not think i ve seen it\n",
      "document index:15 \n",
      "section index:0\n",
      "> do you think i am ok ?\n",
      "Bot: i think it s a great movie . i think it was a great movie . kids are very funny . comedy\n",
      "document index:0\n",
      "section index:0\n",
      "> q\n"
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "sec_encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, sec_encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, sec_encoder, decoder, searcher, voc,wiki_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "l1 = torch.randint(10,(10,))\n",
    "l2 = l1\n",
    "l2, idx1 = torch.sort(l2,descending=True)\n",
    "a = l1.index_select(0,idx1)\n",
    "_, idx2 = torch.sort(idx1)\n",
    "print(l1)\n",
    "print(a)\n",
    "print(l2.index_select(0,idx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# rnn = nn.GRU(10, 20, 2,bidirectional=True)# 2 layers, bidirectional, 10 embedding, 20 hidden\n",
    "# input = torch.randn(5, 3, 10)# sentence length 5, batch 3, embedding 10\n",
    "# h0 = torch.randn(4, 3, 20) # layers 2 * bidirection, batch 3, hidden 20\n",
    "# output, hn = rnn(input, h0) # sentence length 5, batch 3, hidden 20 * bidirection\n",
    "# print(output.shape)\n",
    "# print(hn.shape) # layers 2 * bidirection, batch 3, hidden 20\n",
    "# decoder_input = torch.LongTensor([[3 for _ in range(10)]])\n",
    "# print(decoder_input.shape)\n",
    "\n",
    "hidden = torch.randn(1,5,10)\n",
    "outputs = torch.randn(3,5,10)\n",
    "attn = torch.sum(hidden*outputs,dim=2)\n",
    "print(attn.shape)\n",
    "attn = attn.t()\n",
    "print(attn.shape)\n",
    "r = F.softmax(attn,dim=1).unsqueeze(1)\n",
    "print(r.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
